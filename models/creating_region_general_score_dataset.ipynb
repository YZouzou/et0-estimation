{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88764154",
   "metadata": {},
   "source": [
    "## Creating region general score dataset\n",
    "In this notebook, the predictions of all regional models are combined to get the predictions for all stations. Then, these predictions are used to compute the performance metrics of the regional models combined, which are comparable to the performance metrics computed for the general model. (Remember that the test stations used in regional and general scenarios are the same). Similarly, the general model predictions are separated to compute the performance metrics of the general model for each region, which are comparable to the regional models' performance metrics. The computed metrics are saved in **region_general_scores.csv**, where for each combination of `algorithm`, `region`, `input_combo`, and `dataset` a `region_metric` and a `general_metric` are provided for the regional models and the general model, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d549cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0837f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Path.cwd().parents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490f05aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions(algorithm, region, input_combo):\n",
    "    \n",
    "    if region is None:\n",
    "        region = 'all_data'\n",
    "        \n",
    "    file_name = f\"{algorithm}_{region.lower().replace(' ', '_')}_f{input_combo}.npz\"\n",
    "    pred = np.load(f'models/model_predictions/{file_name}')\n",
    "    \n",
    "    y_hat_train = pred['y_hat_train']\n",
    "    y_hat_test = pred['y_hat_test']\n",
    "    \n",
    "    return y_hat_train, y_hat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f262b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(region):\n",
    "    df = pd.read_csv('processed_data/et_data.csv')\n",
    "    \n",
    "    if region is not None:\n",
    "        cond = df['region'] == region\n",
    "        df = df.loc[cond].reset_index(drop=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d551309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_predictions(data, y_hat_train, y_hat_test):\n",
    "    df = data.copy()\n",
    "    \n",
    "    assert data.shape[0] == y_hat_train.shape[0] + y_hat_test.shape[0], \"The predictions do not match the data\"\n",
    "    \n",
    "    # Slicing train data\n",
    "    cond = df['dataset'] == 'train'\n",
    "    train_data = df.loc[cond]\n",
    "    \n",
    "    # Shuffling train data\n",
    "    train_data = train_data.sample(frac=1, random_state=12).reset_index(drop=True)\n",
    "    train_data['y_hat'] = y_hat_train\n",
    "    \n",
    "    # Slicing test data\n",
    "    cond = df['dataset'] == 'test'\n",
    "    test_data = df.loc[cond].copy()\n",
    "    test_data['y_hat'] = y_hat_test\n",
    "    \n",
    "    df = pd.concat([train_data, test_data], ignore_index=True)\n",
    "    df = df.sort_values(by=['st_num', 'year', 'month']).reset_index(drop=True)\n",
    "    \n",
    "    return df[['region', 'st_num', 'year', 'month', 'dataset', 'ET0', 'y_hat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e104ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_fun_dict={\n",
    "                 'MAE': mean_absolute_error,\n",
    "                 'RMSE': lambda x, y: np.sqrt(mean_squared_error(x, y)),\n",
    "                 'rRMSE': lambda x, y: np.sqrt(mean_squared_error(x, y)) / np.mean(x),\n",
    "                 'NSE': r2_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4611419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_score(algorithm, region, input_combo, dataset, metric):\n",
    "    \n",
    "    df = pd.read_csv('models/model_results/model_scores.csv')\n",
    "    \n",
    "    if region is None:\n",
    "        region = 'all_data'\n",
    "        \n",
    "    model_name = f\"{algorithm}_{region.lower().replace(' ', '_')}_f{input_combo}\"\n",
    "    \n",
    "    cond1 = df['model_name'] == model_name\n",
    "    cond2 = df['dataset'] == dataset\n",
    "    \n",
    "    return df.loc[cond1 & cond2, metric].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "168d94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_general_score(algorithm, input_combo, dataset, score_fun_dict):\n",
    "    \n",
    "    regions_list = ['Mediterranean', 'Marmara', 'Black Sea', 'Central Anatolia',\n",
    "                    'Southeastern Anatolia', 'Eastern Anatolia', 'Aegean']\n",
    "    \n",
    "    # Loading general model predictions\n",
    "    df = load_data(None)\n",
    "    y_hat_train, y_hat_test = load_predictions(algorithm, None, input_combo)\n",
    "    general_preds = merge_predictions(df, y_hat_train, y_hat_test)\n",
    "    \n",
    "    # Slicing the defined dataset predictions\n",
    "    cond = general_preds['dataset'] == dataset\n",
    "    general_preds = general_preds.loc[cond]\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    combined_regional_preds = []\n",
    "    \n",
    "    for region in regions_list:\n",
    "        \n",
    "        result = pd.DataFrame(index=score_fun_dict.keys(), columns=['algorithm', 'region', 'input_combo',\n",
    "                                                                 'dataset'])\n",
    "        # Slicing the defined region\n",
    "        cond = general_preds['region'] == region\n",
    "        sliced_general_preds = general_preds.loc[cond]\n",
    "\n",
    "        # Loading regional model predictions\n",
    "        df = load_data(region)\n",
    "        y_hat_train, y_hat_test = load_predictions(algorithm, region, input_combo)\n",
    "        regional_preds = merge_predictions(df, y_hat_train, y_hat_test)\n",
    "\n",
    "        # Slicing the defined dataset predictions\n",
    "        cond = regional_preds['dataset'] == dataset\n",
    "        regional_preds = regional_preds.loc[cond]\n",
    "\n",
    "        for metric, fun in score_fun_dict.items():\n",
    "            result.loc[metric, 'region_metric'] = fun(regional_preds['ET0'], regional_preds['y_hat'])\n",
    "            result.loc[metric, 'general_metric'] = fun(sliced_general_preds['ET0'], sliced_general_preds['y_hat'])\n",
    "\n",
    "        result['region'] = region\n",
    "        \n",
    "        df_list.append(result.reset_index().rename(columns={'index': 'metric'}))\n",
    "        combined_regional_preds.append(regional_preds)\n",
    "    \n",
    "    # Combining metric dataframes of all regions\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Combining regional model prediciotns\n",
    "    combined_regional_preds = pd.concat(combined_regional_preds, ignore_index=True)\n",
    "    \n",
    "    # Computing the total scores for regional and general models\n",
    "    result = pd.DataFrame(index=score_fun_dict.keys(), columns=['algorithm', 'region', 'input_combo',\n",
    "                                                                 'dataset'])\n",
    "    for metric, fun in score_fun_dict.items():\n",
    "            result.loc[metric, 'region_metric'] = fun(combined_regional_preds['ET0'], combined_regional_preds['y_hat'])\n",
    "            result.loc[metric, 'general_metric'] = fun(general_preds['ET0'], general_preds['y_hat'])\n",
    "    \n",
    "    result['region'] = 'all_data'\n",
    "    \n",
    "    df = pd.concat([df, result.reset_index().rename(columns={'index': 'metric'})], ignore_index=True)\n",
    "    \n",
    "    df['algorithm'] = algorithm\n",
    "    df['input_combo'] = input_combo\n",
    "    df['dataset'] = dataset\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eadab38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe\n",
    "df_list = []\n",
    "algorithms = ['SVR', 'GPR', 'RF', 'Polynomial']\n",
    "\n",
    "# for algorithm in algorithms:\n",
    "#     for input_combo in range(1, 17):\n",
    "#         for dataset in ['train', 'test']:\n",
    "#             df_list.append(get_cluster_general_score(algorithm, input_combo, dataset, score_fun_dict))\n",
    "            \n",
    "# result = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91092e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
